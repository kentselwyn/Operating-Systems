# Operating Systems Weekly Review 14  

# 1. Definitions and Short Answers  

1. What is the purpose of Unix file API `tell()`, which can be accessed from Python as `fh.tell()` on a file handle `fh`?  

> The API `tell()` gets the current position of the file head.  

2. What is the meaning of the `whence` parameter in a `seek()` call?  

> `whence` in a `seek()` call determines the relative position of file head displacement. It can be three values: 0 (by default), 1, and 2.

- How do you move the file head to the end of the file?  

> When `whence` is 2, the displacement is relative to the end of the file. Therefore, `seek(0, whence=2)` moves the file head to the end of the file.  

- How do you move the file head to the beginning of the file?  

> When `whence` is 0 (by default), the displacement is relative to the beginning of the file. Therefore, `seek(0, whence=0)` moves the file head to the beginning of the file.  

- How do you move the file head to 10 bytes after the current position?  

> When `whence` is 1, the displacement is relative to the current position. Therefore, `seek(10, whence=1)` moves the file head 10 bytes after the current position.  

3. Is a file deleted when it is deleted from a directory? If not always, under what condition is it really deleted?  

> A file is not deleted when it is deleted from a directory if there is at least one other reference to it. When there is only one reference to the deleted file, it is really deleted.  

4. What is the difference between **tree-structured directories** and **acyclic-graph directories**?  

> Tree-structured directories allow each node (subdirectories or files) to have only one parent (directory), while acyclic-graph directories allow each node (subdirectories or files) to have multiple parents (directories). That is, directories can have shared subdirectories and files.  

5. What is the purpose of using reference count for files? Is it a good solution for acyclic-graph directories? What about cyclic-graph directories?  

> Reference count for files keeps track of how many directories have reference to themselves. Using reference count for acyclic-graph directories is a practical solution. However, it fails in cyclic-graph directories due to cycles. Files that are in cycles that are disconnected from the root tree have reference count larger than zero, but are virtually inaccessible.  

6. One way of implementing access control in file systems is Access Control List (ACL). What is its content and why is it too complex to specify?

> Access Control List, abbreviated as ACL, contains the list of users and their corresponding allowed access modes for each file. However, it is not scallable when the number of users becomes large, as the list becomes large for multiple files.  

7. What is UNIX's solution to ACL?  

> UNIX used owner-group-public ACL, a condensed version of ACL.  

- How many bits per file does Unix use to represent the access right of different kinds of users (without considering whether an entry is a directory or a file)? What does each bit represent?  

> UNIX used three bits for three different types of users (Owner, Group, and Others). The first bit represents the read access, the second bit represents the write access, and the third bit represents the execute access.  

- Is a "group" defined by the file system? Who gets to define a group? Who gets to associate a file with a group?  

> A group is a set of user IDs that are defined by the sysadmin. The owner can associate a file with a group.  

- If a user is not a member of the group of a file, can the user still access the file? How?  

> A user that is not a member of the group of a file can possibly access the file using the permission of the Others type of user.  

8. Fill out the following table for each of the following types of on-disk structures:

| Name | Also known as | Purpose | One per unit |
| :-: | :-: | :-: | :-: |
| Boot control block | N/A | Contains information needed by system to boot the operating system from that volume | Per volume or per partition |
| Volume control block | Partition control block | Contain volume details (total block count, total free block count, block size, free block pointers) | Per volume |
| Directory control block | N/A | Tracks all different directories (names, inode numbers, and master file tables) | Per file system |
| File control block | Inodes | Tracks the Inode ID, permission, size, dates, Access Control List | Per file |

9. Fill out the following table for each of the following types of in-memory structures maintained by the file system.  

| Table | Content | One per unit |
| :-: | :-: | :-: |
| Mount table | File system mounts, mounting points, file system types | One per file system |  
| In-memory directory structure | A set of recently accessed directories | N/A |  
| System-wide open-file table | A copy of each open file's FCB | One per file-system |  
| Per-process open-file table | File handler (pointer) to corresponding entry in system-wide table | One per process |  
| Buffers | Data blocks from secondary storage | N/A |  

10. In **contiguous allocation** of disk blocks,  
- Why is it "best performance in most cases"?  

> Because contiguous allocation is simple and straightforward. Block allocation requires only starting address and the required number of blocks.

- Why is it difficult to implement in practice?  

> In contiguous allocation, there are external fragmentation problem. There is no way to predict the allocated block size in advance. Therefore, compaction is needed either offline or online, which may lead to poor performance. 

11. In linked allocation of disk blocks,  
- How does it solve the problem of external fragmentation with contiguous allocation?  

> Disk blocks of one same file no longer need to be allocated in contiguous blocks.  

- Why is it not so good for random access?  

> In linked allocation of disk blocks, a file is a linked list of blocks. Therefore, the time needed for random access is linear traversal of all blocks at worst case.  

- Why is reliability a potential issue?  

> An erroneous link can cause the whole file to be broken.  

12. What does FAT stand for?  

> FAT stands for File Allocation Table.  

13. Is FAT more like contiguous allocation or linked allocation? How is it different and what does it improve?  

> File Allocation Table (FAT) is conceptually still a linked allocation. Instead of placing the links (or pointers) in each file block, FAT is located in the beginning of the volume and contains the table of all links. This enables FAT to be easily cached and simple new block allocation.  

14. What is a potential disadvantage with FAT for Flash-based storage?  

> For Flash-based storage, FAT blocks may get more wear-and-tear due to being read and written more frequently than other blocks. If the FAT is corrupted, then the entire file system collapses due to missing links.  

15. In indexed allocation, How is its random access performance compared to that of linked allocation? Does an index table use more or less space on disk compared to linked allocation and why?  

> In indexed allocation, each file has its own index table and random access is as simple as looking into the table. Therefore, its random access performance is more efficient than that of linked allocation. However, an index table uses more disk space than linked allocation due to internal fragmentation, because it is unclear how large the index table should be.  

16. Is a UNIX inode more like contiguous allocation? linked allocation? indexed allocation? multi-level indexed allocation? or some combination?  

> UNIX inodes are the combination of indexed allocation and multi-level indexed allocation. It contains 12 entries of direct blocks (an indexed allocation) and single-, double-, and triple-indirect blocks (multi-level indexed allocation).  

17. What is the difference between a buffer cache and a page cache? What is each one used for?  

> A buffer cache caches the disk blocks for the file system, while a page cache caches file data as pages for the virtual memory system.  

18. Describe a situation where double caching can happen in buffer cache and page cache.  

> Double caching occurs when a memory-mapped I/O for a file in disk. The memory-mapped I/O will be handled by the page cache, then handled by the buffer cache for I/O to the disk. Therefore, the same content is cached twice in both the page and buffer caches.  

19. Why is LRU a bad idea as a policy for page cache replacement for sequential access?  

> In sequential access, recently used blocks are unlikely to be used again soon. Therefore, keeping recently used blocks helps with nothing.  

20. Is asynchronous or synchronous file writes more common and for what reason?  

> Asynchronous write is more common. It allows writes to be buffered in buffer caches, and can schedule the writes to occur in a suitable time.  

21. Does synchrony impact file-read performance? If not, what can improve read performance?  

> Synchrony does not impact file-read performance. Prefetching can improve file-read performance.  

22. In a journaling file system, what happens when the system crashes before some metadata can be updated consistently?  

> In a journaling file system, metadat updates, also known as transactions, are recorded asynchronously by the file system. When a system crash occurs, transactions that are in the log are transactions that have not yet taken place on the file system. Therefore, the remaining updates can still be recovered with the log.  

23. How does WAFL file system take snapshots?  

> Snapshots inodes keep track of pointers that point to old blocks.  

24. Why is copy-on-write automatic in WAFL?  

> WAFL maintains the same blocks that are untouched by writes, but allocates new blocks for updated blocks on demand. This is exactly what copy-on-write accomplishes.  

25. In NFS or remote file systems, what is the problem with access control by matching user ID between the client and server? What is the solution?  

> In Network File System (NFS), same user may have different user IDs across different machines. Therefore, Network Info Service (NIS) is employed to authenticate users.  

26. In UFS, if multiple users share a file, when is a write visible to the other users? At the time of the write or when the file is closed, or some other time?  

> In UNIX file system (UFS), a write to an open file is immediately visible to other users. This is achieved by a shared file pointer to allow multiple users to read and write concurrently.  

27. In Andrew File System, when are writes are visible to other users? Immediately or when the file is closed or at another time? What are the advantages and disadvantage?  

> In Andrew File System (AFS), a write to an open file is visible only after the file is closed. Its advantage is faster local access speed, but its advantage is that there are multiple existing versions if multiple users write int the same file at the same time.  

28. In NFS, is there a central file server that all clients connect to? If not, how are the different workstations related to each other? Do users see the same or different views of their home directory when logged in from different workstations sharing these files?  

> There is no central file server to connect. Instead, a workstation can mount the file system of other workstations over the network. Therefore, users see exactly the same views of their home directory.  
